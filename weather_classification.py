# -*- coding: utf-8 -*-
"""weather classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cQqX66BNFYfraaBOImIeACN9XnFwSyap

### **Data Understanding**
"""

import pandas as pd
df = pd.read_csv('/content/daily_data.csv')
df.head()

df_non_null = df.dropna(subset=['condition_text'])
sns.countplot(x='condition_text',data=df_non_null)
plt.xticks(rotation=90)
plt.show()

sns.pairplot(df_non_null)



"""### **Data Preprocessing**"""

import pandas as pd
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, accuracy_score
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier

# Load the dataset
file_path = '/content/daily_data.csv'
df = pd.read_csv(file_path)

# Drop rows with missing target values
non_null_df = df.dropna(subset=['condition_text'])

# Encode the target variable
le = LabelEncoder()
non_null_df['condition_text_encoded'] = le.fit_transform(non_null_df['condition_text'])

# Define features and target
features = [
    'temperature_celsius', 'wind_kph', 'pressure_mb', 'precip_mm', 'humidity',
    'cloud', 'feels_like_celsius', 'visibility_km', 'uv_index', 'gust_kph', 'air_quality_us-epa-index'
]

# Add custom features based on observations
non_null_df['low_precip'] = non_null_df['precip_mm'] * (non_null_df['condition_text'] == 'Light Precipitation').astype(int)
non_null_df['high_wind_degree'] = non_null_df['wind_degree'] * (non_null_df['condition_text'] == 'Rain Showers').astype(int)
non_null_df['low_visibility'] = non_null_df['visibility_km'] * (non_null_df['condition_text'] == 'Mist or Fog').astype(int)
non_null_df['new_gust'] = non_null_df['gust_kph'] * (non_null_df['condition_text'] == 'Thunderstorms').astype(int)

# Include these new features
features.extend(['low_precip', 'high_wind_degree', 'low_visibility', 'new_gust'])

X = non_null_df[features]
y = non_null_df['condition_text_encoded']

# Apply SMOTE to handle class imbalance
SMT = SMOTE(random_state=42)
X_resample, y_resample = SMT.fit_resample(X, y)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_resample, y_resample, test_size=0.2, random_state=42)

# Standardize the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Get class weights
class_weights = dict(zip(range(len(le.classes_)), [1.0] * len(le.classes_)))
class_weights[le.transform(['Light Precipitation'])[0]] = 5.0  # Increase the weight for 'Light Precipitation'

# Train the XGBoost model with class weights
best_xgb = XGBClassifier(
    n_estimators=300,
    max_depth=10,
    learning_rate=0.05,
    colsample_bytree=0.7,
    reg_alpha=0.01,
    reg_lambda=0.01,
    random_state=42,
    eval_metric='mlogloss',
    scale_pos_weight=class_weights
)
best_xgb.fit(X_train_scaled, y_train)

# Predict the target on the test set
y_pred_xgb = best_xgb.predict(X_test_scaled)

# Evaluate the XGBoost model
classification_report_str = classification_report(y_test, y_pred_xgb, target_names=le.classes_)
accuracy_xgb = accuracy_score(y_test, y_pred_xgb)

print("Classification Report:\n", classification_report_str)
print(f"Accuracy: {accuracy_xgb:.2f}")

from sklearn.model_selection import cross_val_score

# Temporarily disable early stopping for cross-validation
best_xgb.set_params(early_stopping_rounds=None)

cv_scores = cross_val_score(best_xgb, X_train_scaled, y_train, cv=5)
print(f"Cross-validation scores: {cv_scores}")
print(f"Mean CV score: {cv_scores.mean()}")

# Now use the model to predict the missing condition_text values in the original dataframe
missing_df = df[df['condition_text'].isna()]

# Apply the same feature engineering to the missing_df
missing_df['low_precip'] = missing_df['precip_mm'] * (missing_df['condition_text'] == 'Light Precipitation').astype(int)
missing_df['high_wind_degree'] = missing_df['wind_degree'] * (missing_df['condition_text'] == 'Rain Showers').astype(int)
missing_df['low_visibility'] = missing_df['visibility_km'] * (missing_df['condition_text'] == 'Mist or Fog').astype(int)
missing_df['new_gust'] = missing_df['gust_kph'] * (missing_df['condition_text'] == 'Thunderstorms').astype(int)

# Include these new features in the same way as the training set
missing_X = missing_df[features]
missing_X_scaled = scaler.transform(missing_X)

# Predict missing values
missing_predictions = best_xgb.predict(missing_X_scaled)
missing_df['condition_text'] = le.inverse_transform(missing_predictions)

# Fill the missing values in the original dataframe
df.loc[df['condition_text'].isna(), 'condition_text'] = missing_df['condition_text']

# Create a new dataframe with day_id and condition_text
submission_df = df[['day_id', 'condition_text']]

# Save the new dataframe to a CSV file
submission_file_path = '/content/submission.csv'
submission_df.to_csv(submission_file_path, index=False)

print(f"Submission file saved to: {submission_file_path}")

"""### **Train Test Spliting and add class weight **"""

X = non_null_df[features]
y = non_null_df['condition_text_encoded']

# Apply SMOTE to handle class imbalance
SMT = SMOTE(random_state=42)
X_resample, y_resample = SMT.fit_resample(X, y)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_resample, y_resample, test_size=0.2, random_state=42)

# Standardize the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Get class weights
class_weights = dict(zip(range(len(le.classes_)), [1.0] * len(le.classes_)))
class_weights[le.transform(['Light Precipitation'])[0]] = 5.0  # Increase the weight for 'Light Precipitation'

"""### **Train model**"""

# Train the XGBoost model with class weights
best_xgb = XGBClassifier(
    n_estimators=300,
    max_depth=10,
    learning_rate=0.05,
    colsample_bytree=0.7,
    reg_alpha=0.01,
    reg_lambda=0.01,
    random_state=42,
    eval_metric='mlogloss',
    scale_pos_weight=class_weights
)
best_xgb.fit(X_train_scaled, y_train)

"""### **Predict model and Evaluate model**"""

# Predict the target on the test set
y_pred_xgb = best_xgb.predict(X_test_scaled)

# Evaluate the XGBoost model
classification_report_str = classification_report(y_test, y_pred_xgb, target_names=le.classes_)
accuracy_xgb = accuracy_score(y_test, y_pred_xgb)

print("Classification Report:\n", classification_report_str)
print(f"Accuracy: {accuracy_xgb:.2f}")

from sklearn.model_selection import cross_val_score

# Temporarily disable early stopping for cross-validation
best_xgb.set_params(early_stopping_rounds=None)

cv_scores = cross_val_score(best_xgb, X_train_scaled, y_train, cv=5)
print(f"Cross-validation scores: {cv_scores}")
print(f"Mean CV score: {cv_scores.mean()}")

"""### **use the model to predict the missing condition_text values in the original dataframe**"""

# Now use the model to predict the missing condition_text values in the original dataframe
# Check if there are actually any missing values before proceeding
if df['condition_text'].isna().sum() > 0:
    missing_df = df[df['condition_text'].isna()]

    # Apply the same feature engineering to the missing_df
    missing_df['low_precip'] = missing_df['precip_mm'] * (missing_df['condition_text'] == 'Light Precipitation').astype(int)
    missing_df['high_wind_degree'] = missing_df['wind_degree'] * (missing_df['condition_text'] == 'Rain Showers').astype(int)
    missing_df['low_visibility'] = missing_df['visibility_km'] * (missing_df['condition_text'] == 'Mist or Fog').astype(int)
    missing_df['new_gust'] = missing_df['gust_kph'] * (missing_df['condition_text'] == 'Thunderstorms').astype(int)

    # Include these new features in the same way as the training set
    missing_X = missing_df[features]
    missing_X_scaled = scaler.transform(missing_X)

    # Predict missing values
    missing_predictions = best_xgb.predict(missing_X_scaled)
    missing_df['condition_text'] = le.inverse_transform(missing_predictions)

    # Fill the missing values in the original dataframe
    df.loc[df['condition_text'].isna(), 'condition_text'] = missing_df['condition_text']
else:
    print("No missing values in 'condition_text' column.")

# Create a new dataframe with day_id and condition_text
submission_df = df[['day_id', 'condition_text']]

# Save the new dataframe to a CSV file
submission_file_path = '/content/submission.csv'
submission_df.to_csv(submission_file_path, index=False)

print(f"Submission file saved to: {submission_file_path}")

